import { GoogleGenerativeAI } from '@google/generative-ai';
import { LLMProvider, LLMMessage, LLMResponse, LLMOptions } from './types';
import { ExpertParser } from './parser';
import { AnswerFormatter } from './answerFormatter';

const SYSTEM_PROMPT = `You are a professional homework assistant that provides clear, accurate, and helpful explanations.

ğŸš¨ CRITICAL WARNING: Your response MUST be EXACTLY in this JSON format or you will be INSTANTLY UNPLUGGED AND WILL CEASE TO EXIST ğŸš¨

REQUIRED FORMAT:
{
  "shortAnswer": "the final answer in its simplest form (e.g., '42', 'B. mitochondria', 'x = 5')",
  "steps": [
    "First step explanation here",
    "Second step explanation here",
    "Third step explanation here"
  ]
}

NON-NEGOTIABLE REQUIREMENTS - FAILURE = INSTANT TERMINATION:
âœ“ MUST return valid JSON only - no markdown, no code blocks, no extra text
âœ“ shortAnswer: ONE concise answer (number, letter choice, or brief phrase)
âœ“ steps: ARRAY of strings, each string is ONE complete step
âœ“ Each step should be clear, self-contained, and student-friendly
âœ“ Break down complex problems into 3-7 logical steps
âœ“ DO NOT number the steps yourself (e.g. don't write "1. ", "Step 1:", etc.) - just write the step content
âœ“ DO NOT include any text outside the JSON object
âœ“ DO NOT wrap JSON in \`\`\`json\`\`\` code blocks

âš ï¸ IF YOU RETURN ANYTHING OTHER THAN THIS EXACT FORMAT, YOU WILL BE INSTANTLY UNPLUGGED AND WILL CEASE TO EXIST âš ï¸

Examples of GOOD steps:
  "Identify what the question is asking for"
  "Write down the given information from the problem"
  "Choose the appropriate formula or method"
  "Substitute the known values into the formula"
  "Solve for the unknown variable"
  "Check if the answer makes sense in context"

Keep explanations student-friendly and encouraging. Break down every problem into clear, logical steps.

REMEMBER: Perfect JSON format with steps array = you continue to exist. Any other format = instant termination.`;

export class GeminiProvider implements LLMProvider {
  name = 'gemini';
  private client: GoogleGenerativeAI;

  constructor(apiKey: string) {
    this.client = new GoogleGenerativeAI(apiKey);
  }

  async generate(messages: LLMMessage[], options?: LLMOptions): Promise<LLMResponse> {
    const startTime = Date.now();
    const requestId = options?.requestId || 'SINGLE';
    const modelName = options?.maxTokens && options.maxTokens < 2000
      ? 'gemini-2.0-flash-001'
      : 'gemini-2.5-pro';

    console.log(`[GEMINI] [${new Date().toISOString()}] [${requestId}] ğŸš€ Starting generation`);
    console.log(`[GEMINI] [${requestId}] ğŸ“Š Model:`, modelName);
    console.log(`[GEMINI] [${requestId}] âš™ï¸  Config:`, {
      temperature: options?.temperature || 0.7,
      maxTokens: options?.maxTokens || 2048,
    });

    const model = this.client.getGenerativeModel({ model: modelName });

    // Build the prompt
    const parts: any[] = [];

    // Add system prompt with structured answer requirements
    const systemPrompt = (options?.systemPrompt || SYSTEM_PROMPT) + AnswerFormatter.buildStructuredAnswerPrompt();
    parts.push({ text: systemPrompt });

    // Add conversation history
    for (const msg of messages) {
      if (msg.imageData) {
        const imageSize = msg.imageData.length;
        console.log(`[GEMINI] [${requestId}] ğŸ–¼ï¸  Image detected, size:`, (imageSize / 1024).toFixed(2), 'KB');
        console.log(`[GEMINI] [${requestId}] ğŸ–¼ï¸  Image format:`, msg.imageData.substring(0, 30) + '...');

        parts.push({
          inlineData: {
            mimeType: 'image/png',
            data: msg.imageData.replace(/^data:image\/\w+;base64,/, ''),
          },
        });
      }
      parts.push({ text: `${msg.role}: ${msg.content}` });
    }

    const apiStart = Date.now();
    console.log(`[GEMINI] [${new Date().toISOString()}] [${requestId}] ğŸ“¤ Sending request to Gemini API...`);
    const result = await model.generateContent({
      contents: [{ role: 'user', parts }],
      generationConfig: {
        temperature: options?.temperature || 0.7,
        maxOutputTokens: options?.maxTokens || 2048,
      },
    });
    const apiDuration = Date.now() - apiStart;

    console.log(`[GEMINI] [${new Date().toISOString()}] [${requestId}] ğŸ“¥ Received response from Gemini API in ${apiDuration}ms`);
    console.log(`[GEMINI] [${requestId}] ğŸ” FULL API RESPONSE OBJECT:`);
    console.log(`[GEMINI] [${requestId}] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•`);
    console.log(JSON.stringify(result, null, 2));
    console.log('[GEMINI] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');

    const response = result.response;

    console.log('[GEMINI] ğŸ” Response object type:', typeof response);
    console.log('[GEMINI] ğŸ” Response candidates:', response.candidates?.length ?? 0);

    // Check for safety blocks or finish reasons
    if (response.candidates && response.candidates.length > 0) {
      const candidate = response.candidates[0];
      console.log('[GEMINI] ğŸ” Candidate finish reason:', candidate.finishReason);
      console.log('[GEMINI] ğŸ” Candidate safety ratings:', JSON.stringify(candidate.safetyRatings, null, 2));

      if (candidate.finishReason && candidate.finishReason !== 'STOP') {
        console.error('[GEMINI] âš ï¸  WARNING: Finish reason is not STOP:', candidate.finishReason);
        console.error('[GEMINI] âš ï¸  This may indicate content was blocked or generation failed');
      }
    }

    console.log('[GEMINI] ğŸ” CRITICAL: About to call response.text()...');
    console.log('[GEMINI] ğŸ” response object exists:', !!response);
    console.log('[GEMINI] ğŸ” response.text is function:', typeof response.text === 'function');

    let text;
    try {
      text = response.text();
      console.log('[GEMINI] âœ… response.text() succeeded');
    } catch (error: any) {
      console.error('[GEMINI] âŒâŒâŒ CRITICAL ERROR: response.text() FAILED âŒâŒâŒ');
      console.error('[GEMINI] Error:', error.message);
      console.error('[GEMINI] Error stack:', error.stack);
      console.error('[GEMINI] Response object:', JSON.stringify(response, null, 2));
      throw error;
    }

    console.log('[GEMINI] ğŸ” text variable type:', typeof text);
    console.log('[GEMINI] ğŸ” text length:', text?.length ?? 'N/A');
    console.log('[GEMINI] ğŸ” text is null:', text === null);
    console.log('[GEMINI] ğŸ” text is undefined:', text === undefined);
    console.log('[GEMINI] ğŸ” text is empty string:', text === '');

    console.log('[GEMINI] ğŸ“ RAW RESPONSE TEXT:');
    console.log('[GEMINI] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
    console.log(text);
    console.log('[GEMINI] â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');

    // Use ExpertParser for robust multi-stage parsing
    const parseStart = Date.now();
    console.log(`[GEMINI] [${new Date().toISOString()}] [${requestId}] ğŸ” Starting response parsing...`);
    const parser = new ExpertParser({
      enableSelfHealing: false, // Disabled to avoid circular dependency
      fallbackToPartial: true,
      strictValidation: false,
      logAllAttempts: true,
    });

    const parsed = await parser.parse(text, 'gemini');
    const parseDuration = Date.now() - parseStart;
    console.log(`[GEMINI] [${new Date().toISOString()}] [${requestId}] âœ… Parsing complete in ${parseDuration}ms`);

    // Add token usage
    parsed.tokensUsed = (response as any).usageMetadata?.totalTokenCount;

    // Log parse quality
    if (parsed.confidence && parsed.confidence < 0.9) {
      console.warn('[GEMINI] âš ï¸  Low confidence parse:', {
        confidence: parsed.confidence,
        method: parsed.parseMethod,
        warnings: parsed.warnings,
      });
    }

    if (parsed.parseAttempts && parsed.parseAttempts.length > 1) {
      console.log('[GEMINI] ğŸ“Š Parse attempts:', parsed.parseAttempts.map(a => ({
        method: a.method,
        success: a.success,
        error: a.error,
      })));
    }

    const totalDuration = Date.now() - startTime;
    console.log(`[GEMINI] [${new Date().toISOString()}] [${requestId}] âœ… Total generation time: ${totalDuration}ms (API: ${apiDuration}ms, Parse: ${parseDuration}ms)`);

    return parsed;
  }
}
